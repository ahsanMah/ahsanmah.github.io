[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Attempt at blogging"
  },
  {
    "objectID": "posts/simplegnn/index.html",
    "href": "posts/simplegnn/index.html",
    "title": "Building Graph Neural Networks from Scratch",
    "section": "",
    "text": "This is my attempt to understand Graph Neural Nets (GNNs), implementing the building blocks as I go. I have heavily relied on the seminal Neural Message Passing paper(Gilmer et al. 2017) and the excellent Distill post on GNNs(Sanchez-Lengeling et al. 2021) as my sources and I urge readers to look at them."
  },
  {
    "objectID": "posts/simplegnn/index.html#what-is-a-graph-anyway",
    "href": "posts/simplegnn/index.html#what-is-a-graph-anyway",
    "title": "Building Graph Neural Networks from Scratch",
    "section": "1 What is a graph anyway?",
    "text": "1 What is a graph anyway?\nGraphs will always show up in the form of nodes and edges. Either can have features. You can represent your data using a few building blocks:\n\nNode feature matrix\nEdge feature matrix\nGlobal feature vector (optional)\nGraph connectivity\n\nOption 1: Adjacency list\n\nAn array of node pairs \\((u, v)\\) representing an edge \\(u \\rightarrow v\\)\n\nOption 2: Adjacency matrix\n\nAn NxN matrix where each entry gets a 0/1 if there is an edge present in the graph\nNote that these matrices can be huge for large graphs so one may be forced to use adjacency lists in order to even fit the data into a network\n\n\n\nWe will see that connectivity information explicitly determines the types of operations and the order of operations to perform on the node / edge feature tensors.\n\n\n\n\n\n\nNote\n\n\n\nNote that you can have multiple ‘samples’ i.e. many graphs or a single graph. To get multiple samples/batches from a single large graph, you can sample a subgraph. There are many techniques to sample, which are not covered for now.\n\n\n\n1.1 A graph in the wild\nWe can download a public dataset from the torch_geometric package and view how the data is organized. This is the MUTAG which consists of graphs representing different molecules. We have labels associated with each molecule wwhich we can try to learn.\n\n\nCode to download the graph dataset\n# %pip install torch_geometric -q\n\nimport torch\nimport torch_geometric\nimport torch.nn as nn\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nDATASET_PATH = \"/tmp/data\"\n\n# Random number generator for later use\nrand_generator = torch.Generator()\nrand_generator.manual_seed(42)\ntorch.set_printoptions(precision=3)\n\ndataset = torch_geometric.datasets.TUDataset(\nroot=DATASET_PATH, name=\"MUTAG\",\nuse_edge_attr=True, use_node_attr=True\n)\nprint()\nprint(f'Dataset: {dataset}:')\nprint('====================')\nprint(f'Number of graphs: {len(dataset)}')\nprint(f'Number of features: {dataset.num_features}')\nprint(f'Number of classes: {dataset.num_classes}')\n\n\nDownloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\nProcessing...\n\n\n\nDataset: MUTAG(188):\n====================\nNumber of graphs: 188\nNumber of features: 7\nNumber of classes: 2\n\n\nDone!\n\n\n\n\nWe can grab a single graph sample and display its properties\ndata = dataset[0] # Get the first graph object.\n\nprint()\nprint(data)\nprint('=============================================================')\n\n# Gather some statistics about the first graph.\nprint(f'Number of nodes: {data.num_nodes}')\nprint(f'Number of edges: {data.num_edges}')\nprint(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\nprint(f'Has isolated nodes: {data.has_isolated_nodes()}')\nprint(f'Has self-loops: {data.has_self_loops()}')\nprint(f'Is undirected: {data.is_undirected()}')\n\n\n\nData(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n=============================================================\nNumber of nodes: 17\nNumber of edges: 38\nAverage node degree: 2.24\nHas isolated nodes: False\nHas self-loops: False\nIs undirected: True\n\n\n\n\n1.2 Brief Aside: Why use graphs?\nThis is primarily a modeling decision. We want to emphasize the relational properties of the data, and edges essentially define a relation between two entities. We thus force our models to use this connectivity information in some manner. You could ‘flatten’ a graph into nodes with features, and convert each edge into a feature of the node. But this quickly becomes untenable and sparse ($n^2$ features for the existence of each edge alone + all sorts of edge features we are interested in).\n\n\n\nMolecules are often represented as graphs and for good reason. The relationships between each atom is precisely what gives a molecule its properties. The molecule shown above is called Vanillin. You might be able to guess its smell and taste!\n\n\nMolecules provide an illustrative example of the efficiency for modeling the data as graphs and not as “feature matrices”. How should we represent Vanillin in the image above? We could take one element at a time and keep a list of all its features and bonds: Carbon, [is_gas, is_connected_to_Oxygen, is_connected_to_Oxygen_with_double_bond, is_connected_to_Hydrogen, ...]. This could be a huge vector if all connections are considered.\nWe can even forget about the bonds, and the graph structuire will still emerge as an efficient scheme to represent the data. Say our molecule is composed of the elements Carbon, Oxygen, Iron and Aluminum. Should Iron and Aluminum have a ‘static’ feature for representing is_metal? If so, thenCarbon and Oxygen will also need to have a is_metal feature as part of the data representation. It might be more efficient to model “metallicness” as a relation between only the two entities that we care about. You could go on: should every entity have a feature saying is_nobel_gas or an edge connecting the few nobel gases in the dataset? Both techniques are valid, but we humans choose to feed our machines what we have deemed important."
  },
  {
    "objectID": "posts/simplegnn/index.html#graph-neural-networks",
    "href": "posts/simplegnn/index.html#graph-neural-networks",
    "title": "Building Graph Neural Networks from Scratch",
    "section": "2 Graph Neural Networks",
    "text": "2 Graph Neural Networks\nThe basic building blocks of a graph neural network include:\n\nEmbedding layers to learn rich representations of node / edge features\nMessage Passing layers to combine information using the connectivity defined by the graph\n\nThis is the meat and potatoes so to speak\n\nGraph “readout” layers from getting the final prediction\n\n\n2.1 Learn better representations of your input via Embedding Layers\nTransforming input features into inscrutable ‘rich’ representations is the bread and butter of deep learning. So we do the same. We can construct an embedding layer ourselves, using a weight matrix. You can think of this as an MLP / Feed Forward / torch. nn.Linear network with a single hidden layer and no bias. You could also just call it a linear transform but that doesn’t not as fancy.\n\nclass Embedder:\n\n  def __init__(self, n_input, n_hidden):\n    weight_matrix = torch.randn(n_input, n_hidden,\n                       generator=rand_generator)\n    # Adjust weights to keep values small\n    weight_matrix /= n_hidden\n    self.W = torch.nn.Parameter(weight_matrix)\n\n  def __call__(self, x):\n    return torch.mm(x, self.W)\n\nhidden_dims = 5\nnode_embedder = Embedder(n_input=7, n_hidden=hidden_dims)\nedge_embedder = Embedder(n_input=4, n_hidden=hidden_dims)\n\n\n# Grab the nddes and edges from our graph sample\nnodes = data.x\nedges = data.edge_attr\nedge_list = data.edge_index.T\n\nnode_embs = node_embedder(nodes)\nedge_embs = edge_embedder(edges)\n\nnum_edges, num_edge_features = edge_embs.shape\nnode_embs.shape, edge_embs.shape\n\n(torch.Size([17, 5]), torch.Size([38, 5]))\n\n\n\n\n2.2 Combine features via Message Passing\nMessage passing layers are more conceptual than concrete layers like Attention or Convolution Kernels. In the context of GNNs, this concept was popularized by (Gilmer et.al)[https://arxiv.org/abs/1704.01212] in the Message Passing Neural Networks (MPNN) paper. The idea is to use the graph connections in some manner to aggregate information from neighbours.\nThe main idea is to take an edge $e: v w $ and pass the message from the target node \\(w\\) to the source node \\(v\\). We can also use information from the edge itself.\nUnder this lens, we can make the simplest form of message passing by adding information from neighbors and calling it a day.\n\nclass SimpleMessagePasser:\n\n  def __init__(self):\n    pass\n\n  def __call__(self, v, w, e_vw):\n    '''\n    Pass information TO v FROM w, additionally using edge information\n    This implementation does not use v\n    '''\n    m = w + e_vw\n    return m\n  \nmessenger = SimpleMessagePasser()\n\n\n2.2.1 Pass a single message along an edge\nTo see a message creation in action, we can grab an edge from our graph ancd compute embeddings for all entities involved.\n\n# Pick lucky number 13\nedge_idx = 13\n\n# The edge list stores index of the source and target nodes\nnode_v_idx, node_w_idx = edge_list[edge_idx]\n\n# We index into the embedding matrix and grab the corresponding features\nv, w = node_embs[node_v_idx], node_embs[node_w_idx]\ne = edge_embs[edge_idx]\n\n# These should all be of size `hidden_dimension` h\nv.shape, w.shape, e.shape\n\n(torch.Size([5]), torch.Size([5]), torch.Size([5]))\n\n\nPass messages from w to v using e\n\nmessenger(v, w, e).shape\n\ntorch.Size([5])\n\n\n\n\n2.2.2 Pass multiple messages across the entire graph\nOf course a graph has many edges and thus many messages to pass! Using a Tensor library like torch enables us to use clever indexing mechanisms to grab all the messages in one invocation.\n\n# Get indices for *all* nodes with edges\nnode_v_idxs, node_w_idxs = edge_list[:, 0], edge_list[:, 1]\nv, w = node_embs[node_v_idxs], node_embs[node_w_idxs]\n\n# Every edge in order\ne = edge_embs\n\n# Every message from every edge\nmessages = messenger(v, w, e)\nmessages.shape\n\ntorch.Size([38, 5])\n\n\nIf we take a look at all the source nodes, we see that they show up multiple times. This is because they have multiple edges.\n\nnode_v_idxs\n\ntensor([ 0,  0,  1,  1,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  6,  6,  7,  7,\n         8,  8,  8,  9,  9,  9, 10, 10, 11, 11, 12, 12, 12, 13, 13, 14, 14, 14,\n        15, 16])\n\n\nYou can do a quick and dirty count of neighbours for each node by constructing an adjacency matrix like below.\n\nA = torch.zeros(data.num_nodes, data.num_nodes)\nn1, n2 = data.edge_index\nA[n1, n2] = 1\nneighbor_counts = A.sum(axis=1, keepdim=True)\nneighbor_counts.flatten()\n\ntensor([2., 2., 2., 3., 3., 2., 2., 2., 3., 3., 2., 2., 3., 2., 3., 1., 1.])\n\n\nWe thus need to combine the messages or aggregate them in some manner. In deep learning lingo, you can also think of this as ‘pooling’ information from the neighboring nodes. We can also print out embeddings for the last three nodes just to see.\n\nprint(\"Node embeddings before message passing:\")\nprint(node_embs[-3:])\n\n# Aggregate / Pool information from neighboring nodes\n# respecting the neighborhood defined by the graph\n\nfor edge, h_message in zip(edge_list, messages):\n  # Note that node_w will be updated later\n  # when it is the source node in the edge\n  node_v_idx, node_w_idx = edge\n\n  # Aggregation method = sum\n  node_embs[node_v_idx] += h_message\n\n# Normalize by number of neighbors (optional but common)\nnode_embs /= neighbor_counts\n\n# Updated embeddings\nprint(\"========================\")\nprint(\"Node embeddings after message passing:\")\nprint(node_embs[-3:])\n\nNode embeddings before message passing:\ntensor([[-0.247, -0.009, -0.321, -0.150,  0.330],\n        [-0.078, -0.281, -0.146, -0.112, -0.154],\n        [-0.078, -0.281, -0.146, -0.112, -0.154]], grad_fn=&lt;SliceBackward0&gt;)\n========================\nNode embeddings after message passing:\ntensor([[-0.063, -0.038, -0.193, -0.096,  0.103],\n        [-0.554, -0.222, -0.617,  0.300,  0.248],\n        [-0.296, -0.243, -0.465, -0.291,  0.215]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that GNNs often perform many such message passing rounds. For this post, we will only focus on one but there is much flexibility in how one can perform multiple rounds. Again, message passign is more of a concept than a strict methodology.\n\n\n\n\n2.2.3 Brief Aside: Loops can be slow - use fancier methods instead\nThe above method to aggregate messages via iterating over the adjacency list will work but in practice, more efficient methods are used. In particular, Tensor operation libraries like PyTorch have built in methods such as scatter_reduce which will perform the update operations for you, while keeping track of gradients. From the torch documentation, we have the example below. The function allows us to update input (in-place) at position index by using the values from src.\n\nsrc = torch.tensor(  [1., 2., 3., 4., 5., 6.]).requires_grad_(True)\nindex = torch.tensor([0, 1, 0, 1, 2, 1])\ninput = torch.tensor([1., 2., 3., 4.])\ninput.scatter_reduce_(0, index, src, reduce=\"sum\")\n\ntensor([ 5., 14.,  8.,  4.], grad_fn=&lt;ScatterReduceBackward0&gt;)\n\n\nSo at position 0 of input, we have the sum of 1 (from input itself) + 1 (from src[0]) + 3 (from `src[2]). We can even compute gradients like below.\n\ninput[0].backward()\nsrc.grad # Which elements were used to update input 0?\n\ntensor([1., 0., 1., 0., 0., 0.])\n\n\nTo make the computation even clearer, we can step through the process of grabbing the appropriate indices from the edge list and applying the updates via scatter_reduce_.\n\n# We are building the index tensor that will define which node to update\nmessage_target_nodes = torch.zeros(num_edges, num_edge_features, dtype=torch.long)\n\n# Get target node indices from edge list\nmessage_target_nodes[:] = edge_list[:,0].reshape(-1,1)\n\n# E.g. row 3 can be read as: update node at index=1\n# using a message at index=2 from the message tensor\n# The column dimensions can be read as saying\n# ALL columns in message_row=3 will be used to update columns in node_row=1\nmessage_target_nodes[:4]\n\ntensor([[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that we would ideally only need a message-index tensor of shape (num_edges, 1). However, the torch backprop only works when index exactly matches the message shape.\n\n\n\nnode_embs = node_embedder(nodes)\nnode_embs.scatter_reduce_(dim=0, index=message_target_nodes, src=messages,\n                           reduce='sum',include_self=True)\nnode_embs = node_embs / neighbor_counts\nnode_embs[-3:]\n\ntensor([[-0.063, -0.038, -0.193, -0.096,  0.103],\n        [-0.554, -0.222, -0.617,  0.300,  0.248],\n        [-0.296, -0.243, -0.465, -0.291,  0.215]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n\n\n2.3 “Read out” the learned graph embeddings\nThe last block of our humble GNN will be a prediction layer. This will be another transformation to spit out the desired output of the model. In the case of classification, this layer will output the predictions for each class. This is often done per node and then aggregated to compute a graph-level prediction.\n\n# Graph-wise output to predict two classes\npredictor = Embedder(hidden_dims, 2)\ngraph_feature = predictor(node_embs)\noutput_logits = torch.sum(graph_feature, axis=0, keepdim=True)\noutput_logits\n\ntensor([[ -3.639, -18.362]], grad_fn=&lt;SumBackward1&gt;)\n\n\nCheck to see if we can backprop through the whole mechanism\n\noutput_logits.sum().backward()\n\nWe can see that the gradients exist for our edge embedding layer.\n\nedge_embedder.W.grad\n\ntensor([[ 0.731,  9.453, -0.921, 36.528,  7.506],\n        [ 0.107,  1.383, -0.135,  5.346,  1.098],\n        [ 0.071,  0.922, -0.090,  3.564,  0.732],\n        [ 0.000,  0.000,  0.000,  0.000,  0.000]])\n\n\nNote that we could have picked any flavor of prediction function. It could even output the same number of features as the original graph to create a Graph Autoencoder of sorts. this is precisely what we are going to do next to bring everything together!"
  },
  {
    "objectID": "posts/simplegnn/index.html#learn-to-reconstruct-an-input",
    "href": "posts/simplegnn/index.html#learn-to-reconstruct-an-input",
    "title": "Building Graph Neural Networks from Scratch",
    "section": "3 Learn to reconstruct an input",
    "text": "3 Learn to reconstruct an input\nOne of the best methods to test your deep learning model is to check and see whether it can “overfit” to a small batch or even a single sample. We have all the elements for our GNN. Now we can train it to learn to reconstruct the sample graph we have been playing around with.\n\n\nReinitialize our GNN layers and define functions to perform gradient descent\nrand_generator.manual_seed(42)\nhidden_dims = 3\ninput_node_features = 7\ninput_edge_features = 4\nlearning_rate = 1e-2\n\nnode_embedder = Embedder(n_input=input_node_features, n_hidden=hidden_dims)\nedge_embedder = Embedder(n_input=input_edge_features, n_hidden=hidden_dims)\npredictor = Embedder(hidden_dims, input_node_features)\n\nlayers = [\n      node_embedder,\n      edge_embedder,\n      predictor\n]\n\ndef zero_grad(layers):\n  for l in layers:\n    l.W.grad = None\n\n@torch.no_grad\ndef update(layers):\n  '''\n  A basic SGD step!\n  '''\n  for l in layers:\n    l.W.add_(l.W.grad, alpha=-learning_rate)\n\n\n\n# Get the entities of the graph\nnodes = data.x\nedges = data.edge_attr\nedge_list = data.edge_index.T\n\nfor i in range(10_000):\n  zero_grad(layers)\n\n  # Get embeddings\n  node_embs = node_embedder(nodes)\n  edge_embs = edge_embedder(edges)\n\n  # Get edge list and compute messages\n  node_v_idxs, node_w_idxs = edge_list[:,0], edge_list[:,1]\n  v_embs, w_embs = node_embs[node_v_idxs], node_embs[node_w_idxs]\n  messages = messenger(v_embs, w_embs, edge_embs)\n\n  # Get message-target node indices from edge list\n  # i.e. the nodes that will receive the message\n  num_edges, num_message_features = messages.shape\n  message_target_nodes = torch.zeros(num_edges, num_message_features,\n                                     dtype=torch.long, requires_grad=False)\n  message_target_nodes[:] = node_v_idxs.reshape(-1,1)\n\n  # Apply message updates from w to v\n  node_embs.scatter_reduce_(\n      dim=0, index=message_target_nodes,\n      src=messages, reduce='sum', include_self=True\n  )\n\n  # Normalize by number of neighbors\n  node_embs = node_embs / neighbor_counts\n\n  # Get reconstruction\n  node_reconstruction = predictor(node_embs)\n\n  # Compute reconstruction loss\n  loss = (nodes - node_reconstruction).square().sum(axis=1)\n  loss = loss.mean()\n  loss.backward()\n\n  # Gradient step over all parameters\n  update(layers)\n\n  if i % 1000 == 0:\n    print(f\"Step {i:4d}: {loss.item():.3f}\")\n\nStep    0: 1.025\nStep 1000: 0.079\nStep 2000: 0.077\nStep 3000: 0.074\nStep 4000: 0.070\nStep 5000: 0.061\nStep 6000: 0.044\nStep 7000: 0.028\nStep 8000: 0.019\nStep 9000: 0.015\n\n\n\n# Get the last reconstruction\nnode_reconstruction = predictor(node_embs).detach()\nnode_reconstruction.shape\n\ntorch.Size([17, 7])\n\n\n\nfig, axs = plt.subplots(1,2, figsize=(9,3))\nsns.heatmap(nodes, ax=axs[0]);\naxs[0].set_title(\"Original\")\nsns.heatmap(node_reconstruction, ax=axs[1]);\naxs[1].set_title(\"Reconstruction\");\n\n\n\n\nComparing our reconstruction to the original sample\n\n\n\n\nAs we can see the model is able to reproduice the input raesonably well! This is without any fancy optimization, using only one round of message passing and only addition as the message operator and no non-linearities. We actually have a linear model on our hands and it was able to reconstruc the input using the connectivity information from the graph. This is indeed a trite/trivial/contrived example but it gets the point across. We wanted to build a model that could use the structural information present in a graph and we were able to do so.\nWe can use our learnings here to start building more useful GNNs in the next part!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "thoughts",
    "section": "",
    "text": "Building Graph Neural Networks from Scratch\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2024\n\n\nAhsan Mahmood\n\n\n\n\n\n\nNo matching items"
  }
]